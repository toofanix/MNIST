{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST - Bidirectional Recurrent Neural Network\n",
    "\n",
    "Inspired from :\n",
    "    \n",
    "https://github.com/aymericdamien/TensorFlow-Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy  as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No. of training cycles and bacth-size\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100000\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "#Net parameters\n",
    "n_input = 28\n",
    "n_steps = 28\n",
    "n_hidden = 128\n",
    "n_classes = 10\n",
    "\n",
    "#Placeholder for feeding the net\n",
    "x = tf.placeholder(\"float\",[None,n_steps,n_input])\n",
    "y = tf.placeholder(\"float\",[None,n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Weights and biases \n",
    "weights = {'out':tf.Variable(tf.random_normal([2*n_hidden,n_classes]))}\n",
    "biases = {'out':tf.Variable(tf.random_normal([n_classes]))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is 28 X 28 pixels. We consider each row at a sequence with 28 time-steps. Hence, each image will have 28 sequences with 28 steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the input\n",
    "I am using a batch size of 128. Hence, the input will have dimensions of (128,28,28). The LSTM cell requires a list of tensors. In our case the list will have 28 tensors(equal to number of time-steps) with each tensor of dimension (128 X 28). The function below reshapes the input, and return the model for RNN.\n",
    "\n",
    "One thing to remember here is that this is bidirectional. Hence, there are forward and backwards memory cells. Thus, number of hidden weights are 2 X n_hidden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def BiRNN1(x,weights,biases):\n",
    "    x = tf.transpose(x,[1,0,2])\n",
    "    x = tf.reshape(x,[-1,n_input])\n",
    "    x = tf.split(0,n_steps,x)\n",
    "    with tf.variable_scope('forward'):\n",
    "        lstm_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden,forget_bias=1.0)\n",
    "        \n",
    "    with tf.variable_scope('backward'):\n",
    "        lstm_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden,forget_bias=1.0)\n",
    "    \n",
    "    \n",
    "    outputs, _, _ = tf.nn.bidirectional_rnn(lstm_fw_cell,lstm_bw_cell,x,dtype=tf.float32,scope='reuse')\n",
    "    \n",
    "    return (tf.matmul(outputs[-1],weights['out']) + biases['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating the RNN\n",
    "pred = BiRNN1(x,weights,biases)\n",
    "\n",
    "#Optimization routine\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred,y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "#Estimating Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter : 12800  Minibatch loss = 0.636460  Training accuracy = 0.78125\n",
      "Iter : 25600  Minibatch loss = 0.375823  Training accuracy = 0.89062\n",
      "Iter : 38400  Minibatch loss = 0.176354  Training accuracy = 0.93750\n",
      "Iter : 51200  Minibatch loss = 0.133615  Training accuracy = 0.96094\n",
      "Iter : 64000  Minibatch loss = 0.079379  Training accuracy = 0.97656\n",
      "Iter : 76800  Minibatch loss = 0.107371  Training accuracy = 0.96875\n",
      "Iter : 89600  Minibatch loss = 0.101983  Training accuracy = 0.96875\n",
      "Optimization Finished !\n",
      "Testing accuracy : 0.974609375\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    step = 1 \n",
    "    \n",
    "    while step * batch_size < training_epochs:\n",
    "        batch_x , batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        batch_x = batch_x.reshape((batch_size,n_steps,n_input))\n",
    "        \n",
    "        sess.run(optimizer,feed_dict = {x:batch_x,y:batch_y})\n",
    "        \n",
    "        if step % display_step == 0:\n",
    "            acc = sess.run(accuracy,feed_dict={x:batch_x,y:batch_y})\n",
    "            \n",
    "            loss = sess.run(cost,feed_dict={x:batch_x,y:batch_y})\n",
    "            \n",
    "            print (\"Iter : \" + str(step*batch_size) + \n",
    "                  \"  Minibatch loss = {:.6f}\".format(loss) + \n",
    "                  \"  Training accuracy = {:.5f}\".format(acc))\n",
    "        \n",
    "        step += 1\n",
    "    print (\"Optimization Finished !\")\n",
    "    \n",
    "    test_len = 1024\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1,n_steps,n_input))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "    \n",
    "    print (\"Testing accuracy : {}\".format(sess.run(accuracy,feed_dict={x:test_data,y:test_label})))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
